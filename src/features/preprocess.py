"""
ç‰¹å¾µå‰è™•ç†æ¨¡çµ„
è² è²¬å»ºç«‹ ColumnTransformerï¼Œè™•ç†é¡åˆ¥è®Šæ•¸ç·¨ç¢¼ã€æ•¸å€¼è®Šæ•¸ç¸®æ”¾ç­‰
æ”¯æ´è¨“ç·´å’Œé æ¸¬éšæ®µçš„è³‡æ–™å‰è™•ç†
"""

import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder
from sklearn.compose import ColumnTransformer
from sklearn.impute import SimpleImputer
from sklearn.pipeline import Pipeline
import joblib
from pathlib import Path


def get_preprocessor(use_advanced_features=True):
    """
    å»ºç«‹ä¸¦å›å‚³å‰è™•ç†ç®¡ç·š (ColumnTransformer)
    
    Args:
        use_advanced_features (bool): æ˜¯å¦ä½¿ç”¨é€²éšç‰¹å¾µï¼ˆFamilySize, Titleï¼‰
        
    Returns:
        ColumnTransformer: å®Œæ•´çš„å‰è™•ç†ç®¡ç·š
    """
    
    if use_advanced_features:
        # åŒ…å«è¡ç”Ÿç‰¹å¾µçš„ç‰ˆæœ¬
        numeric_features = ['Age', 'Fare', 'SibSp', 'Parch', 'FamilySize']
        categorical_features = ['Sex', 'Embarked', 'Pclass', 'Title']
    else:
        # åŸºæœ¬ç‰¹å¾µç‰ˆæœ¬ï¼ˆé©ç”¨æ–¼å‰›é–‹å§‹çš„è³‡æ–™ï¼‰
        numeric_features = ['Age', 'Fare', 'SibSp', 'Parch']
        categorical_features = ['Sex', 'Embarked', 'Pclass']
    
    # æ•¸å€¼å‹æ¬„ä½çš„è™•ç†ç®¡ç·š
    numeric_transformer = Pipeline(steps=[
        ('imputer', SimpleImputer(strategy='median')),  # ç”¨ä¸­ä½æ•¸å¡«è£œéºå¤±å€¼
        ('scaler', StandardScaler())                    # æ¨™æº–åŒ–
    ])
    
    # é¡åˆ¥å‹æ¬„ä½çš„è™•ç†ç®¡ç·š  
    categorical_transformer = Pipeline(steps=[
        ('imputer', SimpleImputer(strategy='most_frequent')),  # ç”¨æœ€å¸¸è¦‹å€¼å¡«è£œ
        ('onehot', OneHotEncoder(drop='first', sparse_output=False, handle_unknown='ignore'))
    ])
    
    # çµ„åˆæˆ ColumnTransformer
    preprocessor = ColumnTransformer(
        transformers=[
            ('num', numeric_transformer, numeric_features),
            ('cat', categorical_transformer, categorical_features)
        ],
        remainder='drop'  # å…¶ä»–æ¬„ä½éƒ½ä¸Ÿæ‰
    )
    
    return preprocessor


def create_basic_features(df):
    """
    å»ºç«‹åŸºæœ¬çš„è¡ç”Ÿç‰¹å¾µ
    
    Args:
        df (pd.DataFrame): è¼¸å…¥è³‡æ–™
        
    Returns:
        pd.DataFrame: åŠ ä¸Šè¡ç”Ÿç‰¹å¾µçš„è³‡æ–™
    """
    df = df.copy()
    
    # 1. FamilySize: å®¶åº­äººæ•¸
    df['FamilySize'] = df['SibSp'] + df['Parch'] + 1
    
    # 2. IsAlone: æ˜¯å¦ç¨è‡ªä¸€äºº
    df['IsAlone'] = (df['FamilySize'] == 1).astype(int)
    
    # 3. Title: å¾å§“åæå–ç¨±è¬‚
    if 'Name' in df.columns:
        df['Title'] = df['Name'].str.extract(r' ([A-Za-z]+)\.', expand=False)
        
        # ç°¡åŒ–ç¨±è¬‚åˆ†é¡
        title_mapping = {
            'Mr': 'Mr',
            'Miss': 'Miss', 
            'Mrs': 'Mrs',
            'Master': 'Master',
            'Dr': 'Rare',
            'Rev': 'Rare',
            'Col': 'Rare',
            'Major': 'Rare',
            'Mlle': 'Miss',
            'Countess': 'Rare',
            'Ms': 'Miss',
            'Lady': 'Rare',
            'Jonkheer': 'Rare',
            'Don': 'Rare',
            'Dona': 'Rare',
            'Mme': 'Mrs',
            'Capt': 'Rare',
            'Sir': 'Rare'
        }
        
        df['Title'] = df['Title'].map(title_mapping).fillna('Rare')
    
    # 4. Age groups: å¹´é½¡åˆ†çµ„
    if 'Age' in df.columns:
        df['AgeGroup'] = pd.cut(df['Age'], 
                               bins=[0, 12, 18, 35, 60, np.inf], 
                               labels=['Child', 'Teen', 'Adult', 'Middle', 'Senior'])
        df['AgeGroup'] = df['AgeGroup'].astype(str)
    
    # 5. Fare groups: ç¥¨åƒ¹åˆ†çµ„
    if 'Fare' in df.columns:
        df['FareGroup'] = pd.qcut(df['Fare'].fillna(df['Fare'].median()), 
                                 q=4, labels=['Low', 'Medium', 'High', 'VeryHigh'])
        df['FareGroup'] = df['FareGroup'].astype(str)
    
    return df


def preprocess_data(df, preprocessor=None, is_training=True, use_advanced_features=True):
    """
    ä½¿ç”¨ ColumnTransformer å‰è™•ç†è³‡æ–™
    
    Args:
        df (pd.DataFrame): è¼¸å…¥è³‡æ–™
        preprocessor: å·²è¨“ç·´çš„å‰è™•ç†å™¨ï¼Œå¦‚æœæ˜¯ None æœƒå»ºç«‹æ–°çš„
        is_training (bool): æ˜¯å¦ç‚ºè¨“ç·´è³‡æ–™ï¼ˆæ±ºå®šè¦ä¸è¦ fitï¼‰
        use_advanced_features (bool): æ˜¯å¦ä½¿ç”¨é€²éšç‰¹å¾µ
        
    Returns:
        tuple: (è™•ç†å¾Œçš„ç‰¹å¾µçŸ©é™£, å‰è™•ç†å™¨, ç‰¹å¾µåç¨±)
    """
    
    # å»ºç«‹è¡ç”Ÿç‰¹å¾µ
    if use_advanced_features:
        df_processed = create_basic_features(df)
    else:
        df_processed = df.copy()
    
    # å»ºç«‹æˆ–ä½¿ç”¨ç¾æœ‰çš„å‰è™•ç†å™¨
    if preprocessor is None:
        preprocessor = get_preprocessor(use_advanced_features)
    
    if is_training:
        # è¨“ç·´æ™‚ï¼šfit_transform
        X_processed = preprocessor.fit_transform(df_processed)
        print(f"âœ… è¨“ç·´è³‡æ–™å‰è™•ç†å®Œæˆï¼Œå½¢ç‹€: {X_processed.shape}")
    else:
        # æ¸¬è©¦æ™‚ï¼šåª transform
        X_processed = preprocessor.transform(df_processed)
        print(f"âœ… æ¸¬è©¦è³‡æ–™å‰è™•ç†å®Œæˆï¼Œå½¢ç‹€: {X_processed.shape}")
    
    # å–å¾—ç‰¹å¾µåç¨±
    feature_names = get_feature_names(preprocessor)
    
    return X_processed, preprocessor, feature_names


def save_preprocessor(preprocessor, filepath):
    """
    å„²å­˜å‰è™•ç†å™¨
    
    Args:
        preprocessor: å·²è¨“ç·´çš„å‰è™•ç†å™¨
        filepath (str or Path): å„²å­˜è·¯å¾‘
    """
    filepath = Path(filepath)
    filepath.parent.mkdir(parents=True, exist_ok=True)
    
    joblib.dump(preprocessor, filepath)
    print(f"âœ… å‰è™•ç†å™¨å·²å„²å­˜åˆ°: {filepath}")


def load_preprocessor(filepath):
    """
    è¼‰å…¥å‰è™•ç†å™¨
    
    Args:
        filepath (str or Path): å‰è™•ç†å™¨æª”æ¡ˆè·¯å¾‘
        
    Returns:
        ColumnTransformer: è¼‰å…¥çš„å‰è™•ç†å™¨
    """
    filepath = Path(filepath)
    
    if not filepath.exists():
        raise FileNotFoundError(f"æ‰¾ä¸åˆ°å‰è™•ç†å™¨æª”æ¡ˆ: {filepath}")
    
    preprocessor = joblib.load(filepath)
    print(f"âœ… å‰è™•ç†å™¨å·²è¼‰å…¥: {filepath}")
    return preprocessor


def get_feature_names(preprocessor):
    """
    å–å¾—è™•ç†å¾Œçš„ç‰¹å¾µåç¨±ï¼ˆç”¨æ–¼è§£é‡‹æ¨¡å‹ï¼‰
    
    Args:
        preprocessor: å·² fit çš„ ColumnTransformer
        
    Returns:
        list: ç‰¹å¾µåç¨±åˆ—è¡¨
    """
    try:
        feature_names = []
        
        # å–å¾—æ•¸å€¼å‹ç‰¹å¾µåç¨±
        if 'num' in preprocessor.named_transformers_:
            num_transformer = preprocessor.named_transformers_['num']
            num_features = preprocessor.transformers_[0][2]  # æ•¸å€¼å‹æ¬„ä½åç¨±
            feature_names.extend(num_features)
        
        # å–å¾—é¡åˆ¥å‹ç‰¹å¾µåç¨±ï¼ˆOneHot å¾Œï¼‰
        if 'cat' in preprocessor.named_transformers_:
            cat_transformer = preprocessor.named_transformers_['cat']
            cat_features = preprocessor.transformers_[1][2]  # é¡åˆ¥å‹æ¬„ä½åç¨±
            
            if hasattr(cat_transformer.named_steps['onehot'], 'get_feature_names_out'):
                # æ–°ç‰ˆæœ¬ sklearn
                cat_names = cat_transformer.named_steps['onehot'].get_feature_names_out(cat_features)
            else:
                # èˆŠç‰ˆæœ¬ sklearn
                cat_names = cat_transformer.named_steps['onehot'].get_feature_names(cat_features)
                
            feature_names.extend(cat_names)
        
        return feature_names
        
    except Exception as e:
        print(f"âš ï¸ ç„¡æ³•å–å¾—ç‰¹å¾µåç¨±: {e}")
        return [f"feature_{i}" for i in range(preprocessor.transform([[0]*len(preprocessor.transformers_[0][2])]).shape[1])]


def get_preprocessing_info(preprocessor):
    """
    é¡¯ç¤ºå‰è™•ç†å™¨çš„è©³ç´°è³‡è¨Š
    
    Args:
        preprocessor: ColumnTransformer å‰è™•ç†å™¨
    """
    print("\nğŸ“Š å‰è™•ç†å™¨è³‡è¨Š:")
    print("=" * 50)
    
    for name, transformer, columns in preprocessor.transformers:
        print(f"\nğŸ”¹ {name.upper()} è½‰æ›å™¨:")
        print(f"   æ¬„ä½: {columns}")
        print(f"   æ­¥é©Ÿ:")
        for step_name, step_transformer in transformer.steps:
            print(f"     - {step_name}: {step_transformer}")
    
    print(f"\nğŸ”¹ å…¶ä»–è™•ç†: {preprocessor.remainder}")


def validate_data_for_preprocessing(df, required_columns=None):
    """
    é©—è­‰è³‡æ–™æ˜¯å¦é©åˆé€²è¡Œå‰è™•ç†
    
    Args:
        df (pd.DataFrame): è¼¸å…¥è³‡æ–™
        required_columns (list): å¿…è¦çš„æ¬„ä½åˆ—è¡¨
        
    Returns:
        tuple: (æ˜¯å¦æœ‰æ•ˆ, éŒ¯èª¤è¨Šæ¯)
    """
    if required_columns is None:
        required_columns = ['Age', 'Fare', 'SibSp', 'Parch', 'Sex', 'Embarked', 'Pclass']
    
    missing_columns = [col for col in required_columns if col not in df.columns]
    
    if missing_columns:
        error_msg = f"ç¼ºå°‘å¿…è¦æ¬„ä½: {missing_columns}"
        return False, error_msg
    
    if df.empty:
        return False, "è³‡æ–™ç‚ºç©º"
    
    return True, "è³‡æ–™é©—è­‰é€šé"


if __name__ == "__main__":
    # æ¸¬è©¦ç”¨ç¨‹å¼ç¢¼
    print("ğŸ§ª æ¸¬è©¦å‰è™•ç†å™¨...")
    
    # æ¸¬è©¦åŸºæœ¬ç‰ˆæœ¬
    print("\n1. æ¸¬è©¦åŸºæœ¬å‰è™•ç†å™¨:")
    basic_preprocessor = get_preprocessor(use_advanced_features=False)
    get_preprocessing_info(basic_preprocessor)
    
    # æ¸¬è©¦é€²éšç‰ˆæœ¬
    print("\n2. æ¸¬è©¦é€²éšå‰è™•ç†å™¨:")
    advanced_preprocessor = get_preprocessor(use_advanced_features=True)
    get_preprocessing_info(advanced_preprocessor)
    
    # æ¸¬è©¦ç‰¹å¾µå»ºç«‹
    print("\n3. æ¸¬è©¦ç‰¹å¾µå»ºç«‹:")
    sample_data = pd.DataFrame({
        'Age': [22, 35, np.nan],
        'Fare': [7.25, 71.83, 8.05],
        'SibSp': [1, 1, 0],
        'Parch': [0, 0, 0],
        'Sex': ['male', 'female', 'male'],
        'Embarked': ['S', 'C', 'Q'],
        'Pclass': [3, 1, 3],
        'Name': ['Braund, Mr. Owen Harris', 'Smith, Mrs. John', 'Johnson, Miss. Emily']
    })
    
    enhanced_data = create_basic_features(sample_data)
    print("æ–°å¢çš„ç‰¹å¾µ:")
    new_columns = set(enhanced_data.columns) - set(sample_data.columns)
    for col in new_columns:
        print(f"  - {col}: {enhanced_data[col].tolist()}")
    
    print("\nğŸ‰ å‰è™•ç†å™¨æ¸¬è©¦å®Œæˆï¼")